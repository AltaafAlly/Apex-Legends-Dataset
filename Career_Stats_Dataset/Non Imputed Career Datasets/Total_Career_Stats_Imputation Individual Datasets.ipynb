{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor, HistGradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBRegressor\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from sklearn.exceptions import ConvergenceWarning  # Importing ConvergenceWarning\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use correct relative paths for the CSV files\n",
    "df_xbox = \"Non Imputed Career Datasets/Career_Stats_Xbox.csv\"\n",
    "df_ps4 = \"Non Imputed Career Datasets/Career_Stats_PS4.csv\"\n",
    "df_pc = \"Non Imputed Career Datasets/Career_Stats_PC.csv\"\n",
    "# Read the CSV files\n",
    "df_xbox = pd.read_csv(df_xbox)\n",
    "df_ps4 = pd.read_csv(df_ps4)\n",
    "df_pc = pd.read_csv(df_pc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(output_dir, exist_ok=True)\n",
    "# Instead of combining, process each dataset individually\n",
    "datasets = {\n",
    "    \"Xbox\": df_xbox,\n",
    "    \"PS4\": df_ps4,\n",
    "    \"PC\": df_pc\n",
    "}\n",
    "\n",
    "imputed_dataframes = {}\n",
    "\n",
    "for name, df in datasets.items():\n",
    "    print(f\"Processing {name} dataset...\")  # Debug print\n",
    "    # Convert relevant columns to numeric\n",
    "    df['career_kills'] = pd.to_numeric(df['career_kills'], errors='coerce')\n",
    "    df['career_wins'] = pd.to_numeric(df['career_wins'], errors='coerce')\n",
    "    df['career_revives'] = pd.to_numeric(df['career_revives'], errors='coerce')\n",
    "\n",
    "    # Replace 0s with NaN to treat them as missing values\n",
    "    df.replace(0, np.nan, inplace=True)\n",
    "\n",
    "    # Drop the player_name column for imputation\n",
    "    player_names = df['player_name']\n",
    "    numeric_df = df.drop(columns=['player_name'])\n",
    "\n",
    "    # Mode Imputation\n",
    "    mode_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "    df_mode_imputed = pd.DataFrame(mode_imputer.fit_transform(numeric_df), columns=numeric_df.columns)\n",
    "    df_mode_imputed.insert(0, 'player_name', player_names)\n",
    "    df_mode_imputed.iloc[:, 1:] = df_mode_imputed.iloc[:, 1:].round(0).astype(int)\n",
    "\n",
    "    # Logistic Regression Imputation\n",
    "    lr_imputer = IterativeImputer(estimator=LogisticRegression(solver='lbfgs'), random_state=42, max_iter=10, verbose=0)\n",
    "    df_lr_imputed = pd.DataFrame(lr_imputer.fit_transform(numeric_df), columns=numeric_df.columns)\n",
    "    df_lr_imputed.insert(0, 'player_name', player_names)\n",
    "    df_lr_imputed.iloc[:, 1:] = df_lr_imputed.iloc[:, 1:].round(0).astype(int)\n",
    "\n",
    "    # Random Forest Imputation\n",
    "    rf_imputer = IterativeImputer(estimator=RandomForestClassifier(n_estimators=10), random_state=42, max_iter=10, verbose=0)\n",
    "    df_rf_imputed = pd.DataFrame(rf_imputer.fit_transform(numeric_df), columns=numeric_df.columns)\n",
    "    df_rf_imputed.insert(0, 'player_name', player_names)\n",
    "    df_rf_imputed.iloc[:, 1:] = df_rf_imputed.iloc[:, 1:].round(0).astype(int)\n",
    "\n",
    "    # KNN Imputation\n",
    "    knn_imputer = KNNImputer(n_neighbors=5)\n",
    "    df_knn_imputed = pd.DataFrame(knn_imputer.fit_transform(numeric_df), columns=numeric_df.columns)\n",
    "    df_knn_imputed.insert(0, 'player_name', player_names)\n",
    "    df_knn_imputed.iloc[:, 1:] = df_knn_imputed.iloc[:, 1:].round(0).astype(int)\n",
    "\n",
    "    # Mean Imputation\n",
    "    mean_imputer = SimpleImputer(strategy='mean')\n",
    "    df_mean_imputed = pd.DataFrame(mean_imputer.fit_transform(numeric_df), columns=numeric_df.columns)\n",
    "    df_mean_imputed.insert(0, 'player_name', player_names)\n",
    "    df_mean_imputed.iloc[:, 1:] = df_mean_imputed.iloc[:, 1:].round(0).astype(int)\n",
    "\n",
    "    # Median Imputation\n",
    "    median_imputer = SimpleImputer(strategy='median')\n",
    "    df_median_imputed = pd.DataFrame(median_imputer.fit_transform(numeric_df), columns=numeric_df.columns)\n",
    "    df_median_imputed.insert(0, 'player_name', player_names)\n",
    "    df_median_imputed.iloc[:, 1:] = df_median_imputed.iloc[:, 1:].round(0).astype(int)\n",
    "\n",
    "    # XGBoost Imputation\n",
    "    xgb_imputer = IterativeImputer(estimator=XGBRegressor(), random_state=42, max_iter=10, verbose=0)\n",
    "    df_xgb_imputed = pd.DataFrame(xgb_imputer.fit_transform(numeric_df), columns=numeric_df.columns)\n",
    "    df_xgb_imputed.insert(0, 'player_name', player_names)\n",
    "    df_xgb_imputed.iloc[:, 1:] = df_xgb_imputed.iloc[:, 1:].round(0).astype(int)\n",
    "\n",
    "    # MICE Imputation\n",
    "    mice_imputer = IterativeImputer(max_iter=10, random_state=42)\n",
    "    df_mice_imputed = pd.DataFrame(mice_imputer.fit_transform(numeric_df), columns=numeric_df.columns)\n",
    "    df_mice_imputed.insert(0, 'player_name', player_names)\n",
    "    df_mice_imputed.iloc[:, 1:] = df_mice_imputed.iloc[:, 1:].round(0).astype(int)\n",
    "\n",
    "    # Store all rounded imputed dataframes for this dataset\n",
    "    imputed_dataframes[name] = {\n",
    "        \"Mode Imputation\": df_mode_imputed,\n",
    "        \"Logistic Regression Imputation\": df_lr_imputed,\n",
    "        \"Random Forest Imputation\": df_rf_imputed,\n",
    "        \"KNN Imputation\": df_knn_imputed,\n",
    "        \"Mean Imputation\": df_mean_imputed,\n",
    "        \"Median Imputation\": df_median_imputed,\n",
    "        \"XGBoost Imputation\": df_xgb_imputed,\n",
    "        \"MICE Imputation\": df_mice_imputed\n",
    "    }\n",
    "\n",
    "    # Only save the MICE-imputed dataframe for this dataset to the specified directory\n",
    "    mice_csv_path = os.path.join(output_dir, f\"MICE_Imputed_{name}.csv\")\n",
    "    try:\n",
    "        df_mice_imputed.to_csv(mice_csv_path, index=False)\n",
    "        print(f\"MICE-imputed dataset for {name} saved to {mice_csv_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to save {name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing values for each original dataset\n",
    "for name, df in datasets.items():\n",
    "    print(f\"\\n{name} - Missing entries per column:\")\n",
    "    print(df.isnull().sum())\n",
    "    total_missing = df.isnull().sum().sum()\n",
    "    print(f\"{name} - Total missing entries: {total_missing}\")\n",
    "\n",
    "# Check that there are no missing values in each imputed dataframe for each dataset\n",
    "for dataset_name, imputations in imputed_dataframes.items():\n",
    "    print(f\"\\nChecking imputed dataframes for {dataset_name}:\")\n",
    "    for method_name, imputed_df in imputations.items():\n",
    "        missing = imputed_df.isnull().sum().sum()\n",
    "        print(f\"  {method_name}: {missing} missing values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_correlation_heatmap(df, title):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(df.corr(), annot=True, cmap=\"coolwarm\", fmt='.2f')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "for name, df in datasets.items():\n",
    "    print(f\"\\n{name} - Correlation Heatmap BEFORE MICE Imputation:\")\n",
    "    numeric_df = df.drop(columns=['player_name'])\n",
    "    plot_correlation_heatmap(numeric_df, f\"{name} - Before MICE Imputation\")\n",
    "\n",
    "    print(f\"\\n{name} - Correlation Heatmap AFTER MICE Imputation:\")\n",
    "    mice_df = imputed_dataframes[name][\"MICE Imputation\"].drop(columns=['player_name'])\n",
    "    plot_correlation_heatmap(mice_df, f\"{name} - After MICE Imputation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and print mean and variance for only the MICE-imputed datasets for PC, Xbox, and PS4\n",
    "\n",
    "for name in [\"PC\", \"Xbox\", \"PS4\"]:\n",
    "    print(f\"\\n{name} - Mean and Variance (MICE Imputed):\")\n",
    "    mice_df = imputed_dataframes[name][\"MICE Imputation\"].drop(columns=['player_name'])\n",
    "    mean_variance = mice_df.describe().loc[['mean', 'std']].T\n",
    "    mean_variance.columns = ['Mean', 'Variance']\n",
    "    print(mean_variance)\n",
    "                        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
