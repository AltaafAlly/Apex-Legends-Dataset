{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Analysis: Player Legend Statistics\n",
    "\n",
    "This notebook analyzes player performance statistics for various Legends from a gaming dataset. Each legend falls into specific categories: **Assault**, **Skirmisher**, **Support**, **Controller**, and **Recon**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Import and Initial Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load and Combine Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define legend categories\n",
    "legend_categories = {\n",
    "    'Assault': ['Bangalore', 'Fuse', 'Ash', 'Mad Maggie', 'Ballistic'],\n",
    "    'Skirmisher': ['Pathfinder', 'Wraith', 'Octane', 'Revenant', 'Horizon', 'Valkyrie','Alter'],\n",
    "    'Recon': ['Bloodhound', 'Crypto', 'Seer', 'Vantage'],\n",
    "    'Support': ['Gibraltar', 'Lifeline', 'Mirage', 'Loba', 'Newcastle', 'Conduit'],\n",
    "    'Controller': ['Caustic', 'Wattson', 'Rampart', 'Catalyst']\n",
    "}\n",
    "\n",
    "# Flatten the dictionary to map legend to category\n",
    "legend_to_category = {}\n",
    "for category, legends in legend_categories.items():\n",
    "    for legend in legends:\n",
    "        legend_to_category[legend] = category\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "base_path = r\"\"\n",
    "#change this code to now take in player_name as a variable\n",
    "damage_path = os.path.join(base_path, 'Legend Damage')\n",
    "kills_path = os.path.join(base_path, 'Legend Kills')\n",
    "matches_path = os.path.join(base_path, 'Legend Matches Played')\n",
    "wins_path = os.path.join(base_path, 'Legend Wins')\n",
    "# Function to list files in a directory\n",
    "def list_files(directory):\n",
    "    print(f\"Files in {directory}:\")\n",
    "    for f in os.listdir(directory):\n",
    "        print(f)\n",
    "\n",
    "\n",
    "# Initialize an empty list to hold dataframes for each legend\n",
    "legend_dataframes = []\n",
    "\n",
    "# Get list of legends\n",
    "legends = list(legend_to_category.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Loop over each legend\n",
    "for legend in legends:\n",
    "    try:\n",
    "        # Build file paths for the legend\n",
    "        legend_damage_file = os.path.join(damage_path, f\"{legend}_damage.csv\")\n",
    "        legend_kills_file = os.path.join(kills_path, f\"{legend}_kills.csv\")\n",
    "        legend_matches_file = os.path.join(matches_path, f\"{legend}_games_played.csv\")  # Updated suffix\n",
    "        legend_wins_file = os.path.join(wins_path, f\"{legend}_wins.csv\")\n",
    "        \n",
    "        # Check if all files exist\n",
    "        required_files = [legend_damage_file, legend_kills_file, legend_matches_file, legend_wins_file]\n",
    "        missing_files = [f for f in required_files if not os.path.exists(f)]\n",
    "        if missing_files:\n",
    "            print(f\"Data files for legend '{legend}' are missing: {missing_files}. Skipping this legend.\")\n",
    "            continue  # Skip to the next legend if any file is missing\n",
    "        \n",
    "        # Read the data files\n",
    "        df_damage = pd.read_csv(legend_damage_file, header=None, names=['Damage'], skiprows=1)\n",
    "        df_matches = pd.read_csv(legend_matches_file, header=None, names=['Games Played'], skiprows=1)\n",
    "        df_wins = pd.read_csv(legend_wins_file, header=None, names=['Wins'], skiprows=1)\n",
    "\n",
    "        # Custom converter to handle numeric values and ignore non-numeric ones\n",
    "        def convert_number(s):\n",
    "            try:\n",
    "                # Remove commas and quotes, then convert to integer\n",
    "                return int(str(s).replace(',', '').replace('\"', '').strip())\n",
    "            except ValueError:\n",
    "                # Return NaN if conversion fails\n",
    "                return pd.NA\n",
    "\n",
    "        # Read the kills CSV file with the custom converter\n",
    "        df_kills = pd.read_csv(legend_kills_file, header=None, names=['Kills'], converters={0: convert_number}, skiprows=1)\n",
    "\n",
    "        # Combine the data into a single DataFrame, aligning on index (axis=1)\n",
    "        df_legend = pd.concat([df_damage.reset_index(drop=True), \n",
    "                               df_kills.reset_index(drop=True), \n",
    "                               df_matches.reset_index(drop=True), \n",
    "                               df_wins.reset_index(drop=True)], axis=1)\n",
    "\n",
    "        # Add 'legend_name' column to identify the legend in the combined DataFrame\n",
    "        df_legend['legend_name'] = legend\n",
    "\n",
    "        # Append the processed DataFrame to the list\n",
    "        legend_dataframes.append(df_legend)\n",
    "    \n",
    "    except Exception as e:\n",
    "        # Catch any exceptions during processing and print the error\n",
    "        print(f\"An error occurred while processing legend '{legend}': {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all legend dataframes\n",
    "all_legends_df = pd.concat(legend_dataframes, ignore_index=True)\n",
    "# Map legends to categories\n",
    "all_legends_df['Legend_Category'] = all_legends_df['legend_name'].map(legend_to_category)\n",
    "# # List of legends with missing Wins data\n",
    "#legends_missing_wins = ['Ballistic', 'Conduit', 'Alter', 'Newcastle']\n",
    "# Filter out legends with missing Wins data\n",
    "#all_legends_df = all_legends_df[~all_legends_df['legend_name'].isin(legends_missing_wins)]\n",
    "all_legends_df\n",
    "# create the output file path and create the file if it does not exist\n",
    "output_file = os.path.join(base_path, 'all_legends_combined.csv')\n",
    "# Save the combined DataFrame to a CSV file\n",
    "all_legends_df.to_csv(output_file, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  4. Data Cleaning and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing values\n",
    "print(all_legends_df.isnull().sum())\n",
    "\n",
    "# Drop rows with missing data\n",
    "all_legends_df_clean = all_legends_df.dropna()\n",
    "\n",
    "# Verify no missing values\n",
    "print(\"\\nAfter cleaning:\\n\", all_legends_df_clean.isnull().sum())\n",
    "\n",
    "# Check for duplicates\n",
    "duplicates = all_legends_df[all_legends_df.duplicated()]\n",
    "print(f\"\\nNumber of duplicate rows: {len(duplicates)}\")\n",
    "if not duplicates.empty:\n",
    "    print(duplicates)\n",
    "\n",
    "# Remove duplicates\n",
    "all_legends_df = all_legends_df.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Composition Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataset size:\", all_legends_df.shape)\n",
    "print(\"Number of Legends:\", all_legends_df['Legend_Category'].nunique())\n",
    "print(\"\\nCategory Distribution:\\n\", all_legends_df['Legend_Category'].value_counts(normalize=True)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bar Graphs for Metrics per Legend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics to plot\n",
    "metrics = ['Damage', 'Wins', 'Games Played']\n",
    "\n",
    "# Set larger font sizes globally\n",
    "plt.rcParams.update({'axes.labelsize': 14, 'axes.titlesize': 16, 'xtick.labelsize': 12, 'ytick.labelsize': 12})\n",
    "\n",
    "for metric in metrics:\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    \n",
    "    # Aggregate data by Legend (mean values clearly shown)\n",
    "    legend_avg = all_legends_df.groupby('Legend_Category')[metric].mean().sort_values(ascending=False)\n",
    "    \n",
    "    sns.barplot(x=legend_avg.index, y=legend_avg.values, palette='viridis')\n",
    "\n",
    "    # Clear and readable labels\n",
    "    plt.title(f'Average {metric} per Legend')\n",
    "    plt.xlabel('Legend')\n",
    "    plt.ylabel(f'Average {metric}')\n",
    "\n",
    "    # Rotate x-axis labels for better readability\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  5. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic statistical summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_legends_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Increase global font sizes\n",
    "plt.rcParams.update({\n",
    "    'axes.labelsize': 14, \n",
    "    'axes.titlesize': 16, \n",
    "    'xtick.labelsize': 12, \n",
    "    'ytick.labelsize': 12\n",
    "})\n",
    "\n",
    "# Metrics to plot\n",
    "metrics = ['Damage', 'Wins', 'Games Played']\n",
    "\n",
    "for col in metrics:\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.histplot(all_legends_df[col], kde=True, log_scale=True, bins=30, color='skyblue')\n",
    "\n",
    "    plt.title(f'Distribution of {col} (Log Scale)')\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Frequency')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(all_legends_df[['Damage','Kills','Wins','Games Played']].corr(), annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Analysis by Legend Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove commas and convert to integers for the 'Kills' column\n",
    "all_legends_df['Kills'] = all_legends_df['Kills'].str.replace(',', '', regex=False).astype(int)\n",
    "\n",
    "# Now run your aggregation\n",
    "category_stats = all_legends_df.groupby('Legend_Category').agg({\n",
    "    'Damage': ['mean', 'median', 'std'],\n",
    "    'Kills': ['mean', 'median', 'std'],\n",
    "    'Wins': ['mean', 'median', 'std'],\n",
    "    'Games Played': ['mean', 'median', 'std']\n",
    "})\n",
    "\n",
    "print(\"Detailed Statistical Summary per Category:\\n\")\n",
    "display(category_stats)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['Damage', 'Kills', 'Wins', 'Games Played']\n",
    "\n",
    "for metric in metrics:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.boxplot(x='Legend_Category', y=metric, data=all_legends_df, palette='Set2')\n",
    "    plt.title(f'{metric} Distribution by Legend Category')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for category in all_legends_df['Legend_Category'].unique():\n",
    "    plt.figure(figsize=(7,5))\n",
    "    subset = all_legends_df[all_legends_df['Legend_Category'] == category]\n",
    "    sns.heatmap(subset[['Damage','Kills','Wins','Games Played']].corr(), annot=True, cmap='coolwarm')\n",
    "    plt.title(f'Correlation Heatmap for {category} Legends')\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
